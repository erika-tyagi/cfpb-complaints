{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "from torchtext import data\n",
    "\n",
    "import util as util\n",
    "from models import *\n",
    "from deep_main import *\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# CONFIGURE THESE PARAMETERS\n",
    "# DEVELOPING = True\n",
    "DEVELOPING = False\n",
    "WHICH_TASK = \"response\" # also can be \"product\"\n",
    "\n",
    "if DEVELOPING:\n",
    "    # in order: train, validation, test\n",
    "    files = [\"../data/complaints_3k.csv\", \\\n",
    "                \"../data/complaints_500.csv\", \\\n",
    "                \"../data/complaints_1k.csv\"]\n",
    "    BATCH_SIZE = 7\n",
    "    MAX_VOCAB_SIZE = 5000\n",
    "else:\n",
    "    # in order: train, validation, test\n",
    "    files = [\"../data/full_training_set.csv\", \\\n",
    "                \"../data/full_validation_set.csv\", \\\n",
    "                \"../data/full_testing_set.csv\"]    \n",
    "    BATCH_SIZE = 64\n",
    "    MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "USE_CUDA = False\n",
    "INPUT_DIM = MAX_VOCAB_SIZE + 2 # words + pad + unknown\n",
    "NUM_EPOCHS = 1\n",
    "GRAD_CLIP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT = data.Field(sequential=True, tokenize=util.tokenize, lower=True)\n",
    "# OneHotEncoder = data.Pipeline(convert_token=util.one_hot_encode_response)\n",
    "# LABEL = data.LabelField(sequential=False, use_vocab=False, preprocessing=OneHotEncoder)\n",
    "# train_data = load_and_tokenize_data(files[0], TEXT, LABEL, WHICH_TASK)\n",
    "# TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 25002\n",
      "Unique tokens in LABEL vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = preprocess(WHICH_TASK, *files)\n",
    "\n",
    "train_iter, valid_iter, test_iter = data.BucketIterator.splits( \\\n",
    "(train_data, valid_data, test_data), \\\n",
    "sort_key = lambda x: len(x.narrative), \\\n",
    "sort_within_batch=False, \\\n",
    "batch_size = BATCH_SIZE) \n",
    "\n",
    "iters = (train_iter, valid_iter, test_iter)\n",
    "\n",
    "'''\n",
    "DO MODEL RUNS\n",
    "'''\n",
    "\n",
    "\n",
    "if WHICH_TASK == \"response\":\n",
    "    parameters = {\n",
    "        \"model_type\": \"LSTM\", \\\n",
    "        \"vocab_size\": INPUT_DIM, \\\n",
    "        \"embedding_size\": 40, \\\n",
    "        \"hidden_size\": 50, \\\n",
    "        \"num_layers\": 2, \\\n",
    "        \"n_categories\": 5, \\\n",
    "        \"dropout\": 0.5\n",
    "    }\n",
    "elif WHICH_TASK == \"product\":\n",
    "    parameters = {\n",
    "        \"model_type\": \"LSTM\", \\\n",
    "        \"vocab_size\": INPUT_DIM, \\\n",
    "        \"embedding_size\": 40, \\\n",
    "        \"hidden_size\": 50, \\\n",
    "        \"num_layers\": 2, \\\n",
    "        \"n_categories\": 18, \\\n",
    "        \"dropout\": 0.5\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it = iter(train_data)\n",
    "# for i, b in enumerate(it):\n",
    "#     print(b.narrative)\n",
    "#     if i == 3:\n",
    "#         break\n",
    "# b0.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "if WHICH_TASK == \"product\":\n",
    "    # full_product = util.load_model(parameters, \"full_product_LSTM.pt\")\n",
    "    # sample_product = util.load_model(parameters, \"trained_model_product.pt\")\n",
    "elif WHICH_TASK == \"response\"\n",
    "    sample_response = util.load_model(parameters, \"trained_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.compute_accuracy(sample_product, test_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
